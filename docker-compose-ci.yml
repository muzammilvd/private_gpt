services:
  #OLLAMA
  ollama:
    build:
      context: ./ollama
      dockerfile: ./Dockerfile
      args:
        LLM_MODEL: phi3
    image: ollama-s6:phi3_v5
  
  private-gpt:
    build:
      context: ./private-gpt
      dockerfile: ./Dockerfile
    image: private-gpt:phi3_v5
  
  